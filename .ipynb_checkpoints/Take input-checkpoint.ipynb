{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_int_conversion():\n",
    "    #basic characters in all books\n",
    "    unique_chars = [' ', '!', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    #turn characters into integers and integers into characters - chars should be sorted to keep consistency\n",
    "    char_to_int = {}\n",
    "    int_to_char = {}\n",
    "    for i, char in enumerate(sorted(set(unique_chars))):\n",
    "        char_to_int[char] = i\n",
    "        int_to_char[i] = char\n",
    "        \n",
    "    return char_to_int, int_to_char\n",
    "#     print('number of unique characters: ', len(char_to_int)) #should be 48 every time\n",
    "#     print('unique characters: ', list(char_to_int.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a list of all the path weights and the architecture\n",
    "def get_weights_and_arch():\n",
    "    round_path = \"models/\"\n",
    "    model_paths = []\n",
    "    for root, dirs, files in os.walk(round_path):\n",
    "        #file names in files path\n",
    "        for file in files:\n",
    "            if file.endswith('hdf5'):\n",
    "                model_paths.append(root+\"/\"+file)\n",
    "            elif file.endswith('model_8_architecture.json'):\n",
    "                architecture_path = root+\"/\"+file\n",
    "    #sort paths\n",
    "    model_paths.sort()\n",
    "#     print(architecture_path)\n",
    "    \n",
    "#     print(archi_paths[-1])\n",
    "    # load json architecture\n",
    "    json_file = open(architecture_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    #return model paths\n",
    "    return model_paths, loaded_model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates new sentences\n",
    "def create_passage(model, sentence):\n",
    "#     sentence_length=50\n",
    "#     #full passage string\n",
    "#     sentence = create_sentence(sub_books_combined, sentence_length=sentence_length)\n",
    "    sentence_length = len(sentence)\n",
    "    \n",
    "    print('original sentence: ', sentence.split(\"  \")[-1])\n",
    "    print('\\n')\n",
    "    #predict the next 500 characters \n",
    "    gen_sentence = sentence\n",
    "    print(gen_sentence.split(\"  \")[-1], end=\"\", flush=True)\n",
    "    for i in range(300):\n",
    "#     period_cnt = 0\n",
    "#     while period_cnt != 2:\n",
    "        #turn single sentence into model format\n",
    "        x_pred = np.zeros((1, sentence_length, len(char_to_int)))\n",
    "        #fill tensor with correspoinding values\n",
    "        for k, c in enumerate(sentence):\n",
    "            x_ind = char_to_int[c]\n",
    "            x_pred[0, k, x_ind] = 1\n",
    "\n",
    "        #predict next character - returns predicted probabilities\n",
    "        prob_c = model.predict(x_pred, verbose=0)[0]\n",
    "        #turn to float64 - mulitnomial gives error otherwise\n",
    "        prob_c = np.asarray(prob_c).astype('float64')\n",
    "        #sample from the probability - try out difference softmax temperature values - 0.5 produced best results\n",
    "        log_prob = np.log(prob_c) / 0.5\n",
    "        exp_prob = np.exp(log_prob)\n",
    "        pred_prob = exp_prob/np.sum(exp_prob)\n",
    "        #sample from new probability distribution\n",
    "        p = np.random.multinomial(1, pred_prob, 1) \n",
    "        #get the probability position\n",
    "        prob_ind = np.argmax(p)\n",
    "#         print(prob_ind)\n",
    "\n",
    "        #turn prediction into a character\n",
    "        next_c = int_to_char[prob_ind]\n",
    "#         if next_c == '.':\n",
    "#             period_cnt += 1\n",
    "        #add character to generated sentence\n",
    "        gen_sentence += next_c\n",
    "        #get new sentence by sliding to index of sentence\n",
    "        sentence = sentence[1:]+next_c\n",
    "        print(next_c, end=\"\", flush=True)\n",
    "\n",
    "  \n",
    "    return gen_sentence.split(\"  \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sentence():\n",
    "    #take input from user\n",
    "    while True:\n",
    "        sentence = input(\"Type in some text: \")\n",
    "        sent_len = len(sentence)\n",
    "        #check if the user inputed anything\n",
    "        if sent_len > 0:\n",
    "            break\n",
    "        else:\n",
    "            print(\"You didn't enter anything in.\")\n",
    "            time.sleep(1.8)\n",
    "            clear_output()\n",
    "    \n",
    "    #check if the length is less than the length of the sentences the model was trained on\n",
    "    if sent_len < 50:\n",
    "        while sent_len < 50:\n",
    "            sentence = ' ' + sentence\n",
    "            sent_len = len(sentence)\n",
    "    #sentence has more characters than what was trained on\n",
    "    else:\n",
    "        #grab the last 50 characters\n",
    "        sentence = sentence[-50:]\n",
    "    \n",
    "    #lowercase everything\n",
    "    sentence = sentence.lower()\n",
    "        \n",
    "#     print('new_length: ', len(sentence))\n",
    "#     print(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the char to int conversion and vice versa\n",
    "char_to_int, int_to_char = get_char_int_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of all models and the architecture\n",
    "model_paths, loaded_model_json = get_weights_and_arch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #take input sentence from user\n",
    "    sentence = input_sentence()\n",
    "    clear_output()\n",
    "    \n",
    "    #load architecture\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    #pick random weights from list\n",
    "    path = random.choice(model_paths)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path)\n",
    "    print(\"\\n Loaded model from disk: \", path)\n",
    "    \n",
    "    create_passage(loaded_model, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  jeus\n",
      "\n",
      "\n",
      "jeus, i serve the most some contempt of the consideration of the convent and fortune that the feet to so reason to be in the more when a reason, and the doubt of a man will see any one who would say at the point of the age of the rest that we have been a thing to take the course of the charge of his com"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
