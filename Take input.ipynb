{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all books combined:  74454677\n",
      "size of data:  5000000\n"
     ]
    }
   ],
   "source": [
    "#load corpus\n",
    "books_combined = open('books_combined.txt').read()\n",
    "print('length of all books combined: ', len(books_combined))\n",
    "\n",
    "#work with a subset of the corpus - uses too much space otherwise - kernel crashes \n",
    "start_book_ind = 0\n",
    "end_book_ind = 5000000\n",
    "sub_books_combined = books_combined[start_book_ind: end_book_ind]\n",
    "print('size of data: ', len(sub_books_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters:  48\n",
      "unique characters:  [' ', '!', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "unique_chars = [' ', '!', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "#turn characters into integers and integers into characters - chars should be sorted to keep consistency\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "for i, char in enumerate(sorted(set(unique_chars))):\n",
    "    char_to_int[char] = i\n",
    "    int_to_char[i] = char\n",
    "print('number of unique characters: ', len(char_to_int)) #should be 48 every time\n",
    "print('unique characters: ', list(char_to_int.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded model from disk:  models/round8/model_8.h5\n",
      "original sentence:   that pair of stockings, replied the man, and, he \n",
      "\n",
      "\n",
      " that pair of stockings, replied the man, and, he had practised the other in the most officers which i have passed to the thoughts of the one are a great examples he did not say to make so heard this consequence of form of the thing in the means of the subject. he had have lived to the art of this s\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 50\n",
    "\n",
    "# load json and create model architecture\n",
    "architecture_path = \"models/round8/model_8_architecture.json\"\n",
    "json_file = open(architecture_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "path = \"models/round8/model_8.h5\"\n",
    "loaded_model.load_weights(path)\n",
    "print(\"\\n Loaded model from disk: \", path)\n",
    "create_passage(loaded_model, sub_books_combined)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_8_path = \"models/round8/\"\n",
    "model_8_paths = []\n",
    "for root, dirs, files in os.walk(round_8_path):\n",
    "    #file names in files path\n",
    "    for file in files:\n",
    "        if file.endswith('hdf5') and int(file[20:22]) in [15, 25, 38, 42, 44, 45, 47, 50]:\n",
    "            model_8_paths.append(round_8_path + file)\n",
    "#sort paths\n",
    "model_8_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/round8/weights-improvement-15-1.3715-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-38-1.3525-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-42-1.3505-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-44-1.3492-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-45-1.3492-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-47-1.3478-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-50-1.3475-bigger.hdf5']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json architecture\n",
    "architecture_path = \"models/round8/model_8_architecture.json\"\n",
    "json_file = open(architecture_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-15-1.3715-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are exercised in the reason that the belly of the concern of a street, and the contrary and his since a most intentions and chapter ithe applied and service here for the remains of the state of the army as the other expressions and some sincere the most attempt to the contrary of propersent and both t\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-38-1.3525-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are sufficient to animal who was many constance, and so in the concern of the sense who need the soul to him to go and very reason to live with the most concern of the senses of the state of the horses of the silence of princes of the purpose of this soldiers who could say in the contrary and one of p\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-42-1.3505-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are better to defent the subject of other natures of the face of the preting of the first of the complain of the prince who was believed the house of the part so good and the lower thing that he was a strange things of the soul of the head of the army of the second of the most artini and a silence of \n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-44-1.3492-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are not in the state of the contrary of consideration of death, and that i am in his present account of the understanding of an internal and fortune which is so permit with the same soul in the thing of the subject of her the stranger of his end of the stop of the heart happen to the man, the french g\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-45-1.3492-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are well to have go to him to be great with the name of a soldier of the flower handle the final stage of the day who will do with an declare of first from fire and present the perilies, and disposition, and we was the constraint of the child to be there and there in the house, that the other to serve\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are more in care is like the possession of the contempt of the other seconds but others in the second things and the interest of the sense of the least things, the appearance of the stable of the door, and a refuge of proceed the present water that to all the states of the book and the precepts of the\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-50-1.3475-bigger.hdf5\n",
      "original sentence:  arden and gather in the reins; aperitive things ar\n",
      "\n",
      "\n",
      "arden and gather in the reins; aperitive things are not as the story of the nature of the slow singular face for the man with the singutal ordinary of the pale, but they had as so carefully a it of the world honour; and that they have a common, and that i say that i the most of the stead which he had been without his particular thoughts and the gre\n",
      " ---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#load models\n",
    "\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# loaded_model.load_weights(path)\n",
    "\n",
    "gen_sentence = create_sentence(sub_books_combined, sentence_length=50)\n",
    "# create_passage(loaded_model, gen_sentence)\n",
    "\n",
    "\n",
    "for path in model_8_paths:\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path)\n",
    "    print(\"\\n Loaded model from disk: \", path)\n",
    "    create_passage(loaded_model, gen_sentence)\n",
    "    print(\"\\n ---------------------------------------------------------------------\")\n",
    "\n",
    "# compile loaded model\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  my house is next to sally's. she is my best friend\n",
      "\n",
      "\n",
      "my house is next to sally's. she is my best friendships the sole other man had the shelter. the passion of the world, and the first word of all things is the man of the thing to the contrary, of the cure of some mother to carry and compare him to the tongue of the song of the subject, and the singular time and the man is so interrupted up and commo\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  my house is next to sally's. she is my best friend\n",
      "\n",
      "\n",
      "my house is next to sally's. she is my best friendship and the having sand both considerably so proposed to the man valued and a post upon the most fortune to the man and states in the prince of the time the first face of the army of the proper interest of protections to the fatal hands of his faithful warriors and a body of the end of the inconver\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  my house is next to sally's. she is my best friend\n",
      "\n",
      "\n",
      "my house is next to sally's. she is my best friends that they should go at the distance good of the service with a place of confidence of excellent saint monsieur said, as i have not been to live to the end of the brother to the one and band and to the world had he seems to have seen the short command of the possession of the prince of the man was \n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  my house is next to sally's. she is my best friend\n",
      "\n",
      "\n",
      "my house is next to sally's. she is my best friendship of the grass of the listence and more than which is the princes of her manners before the attempt they have more than he performed about the finger of the ambateral, and require manner of the laugh of the man to the laws. the people the same man one of the most age, not so expenses, and the hea\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " Loaded model from disk:  models/round8/weights-improvement-47-1.3478-bigger.hdf5\n",
      "original sentence:  my house is next to sally's. she is my best friend\n",
      "\n",
      "\n",
      "my house is next to sally's. she is my best friends, the time of the fall are hated and said, even the part of the other of the strange and other of the parts, and should have seen a put in better that they will not lay any of the soul of the death of the disposition of the love of better seemed to laugh and having a right in it and the things and \n",
      " ---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# gen_sentence = create_sentence(sub_books_combined, sentence_length=50)\n",
    "# create_passage(loaded_model, gen_sentence)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    path = \"models/round8/weights-improvement-47-1.3478-bigger.hdf5\"\n",
    "    loaded_model.load_weights(path)\n",
    "    print(\"\\n Loaded model from disk: \", path)\n",
    "    create_passage(loaded_model, gen_sentence)\n",
    "    print(\"\\n ---------------------------------------------------------------------\")\n",
    "\n",
    "# compile loaded model\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sentence = \"my house is next to sally's. she is my best friend\"\n",
    "len(gen_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_path = \"models/\"\n",
    "model_paths = []\n",
    "for root, dirs, files in os.walk(round_path):\n",
    "    #file names in files path\n",
    "    for file in files:\n",
    "        if file.endswith('hdf5'):\n",
    "            model_paths.append(root+\"/\"+file)\n",
    "#sort paths\n",
    "model_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/round1/weights-improvement-43-1.4386-bigger.hdf5',\n",
       " 'models/round2/weights-improvement-50-1.4556-bigger.hdf5',\n",
       " 'models/round3/weights-improvement-50-1.4546-bigger.hdf5',\n",
       " 'models/round4/weights-improvement-18-1.4762-bigger.hdf5',\n",
       " 'models/round4/weights-improvement-38-1.4468-bigger.hdf5',\n",
       " 'models/round5/weights-improvement-39-1.4163-bigger.hdf5',\n",
       " 'models/round6/weights-improvement-13-1.4457-bigger.hdf5',\n",
       " 'models/round6/weights-improvement-29-1.4536-bigger.hdf5',\n",
       " 'models/round7/weights-improvement-41-1.3235-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-15-1.3715-bigger.hdf5',\n",
       " 'models/round8/weights-improvement-47-1.3478-bigger.hdf5']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(model_paths))\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/round8/weights-improvement-15-1.3715-bigger.hdf5'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "\n",
      " Loaded model from disk:  models/round4/weights-improvement-38-1.4468-bigger.hdf5\n",
      "original sentence:  lash; and until i got my eye above the window-sill\n",
      "\n",
      "\n",
      "lash; and until i got my eye above the window-silled work          the destroyen  of the world and the marker          for the spread of the signing letter of     long and the law of the morning that are the world which is to this low and a present and the course of each such a works of compariounce the sense of trimed in the places of the united o\n",
      " ---------------------------------------------------------------------\n",
      "11\n",
      "\n",
      " Loaded model from disk:  models/round7/weights-improvement-41-1.3235-bigger.hdf5\n",
      "original sentence:  lash; and until i got my eye above the window-sill\n",
      "\n",
      "\n",
      "lash; and until i got my eye above the window-silly than the account of the word of the first sound of a house to the other missing in the story of a minute to coming a work of consequences and a soul and place that i was the dear story, and i shouldnt speak of the beautiful room, but a russian or the street of alexandrovna in the arm came to the w\n",
      " ---------------------------------------------------------------------\n",
      "11\n",
      "\n",
      " Loaded model from disk:  models/round2/weights-improvement-50-1.4556-bigger.hdf5\n",
      "original sentence:  lash; and until i got my eye above the window-sill\n",
      "\n",
      "\n",
      "lash; and until i got my eye above the window-sill and the way and when he had to the great that the action was the consciousness of the line she was a man the word to its of form to be as for my historian of the french man and at the little distribute and such a commander when the enterall all it was to defence the conscience of the horse who was \n",
      " ---------------------------------------------------------------------\n",
      "11\n",
      "\n",
      " Loaded model from disk:  models/round6/weights-improvement-13-1.4457-bigger.hdf5\n",
      "original sentence:  lash; and until i got my eye above the window-sill\n",
      "\n",
      "\n",
      "lash; and until i got my eye above the window-silly the times of heaven. mrs. page, i pray you confess his heart and her out of the dear streat the lords shall i found it. a crown so was in his tarry with the most desires of this rest that i have loved the heart, and be bend my side in my shore be heart to the person the time with the court, and he\n",
      " ---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gen_sentence = create_sentence(sub_books_combined, sentence_length=50)\n",
    "# create_passage(loaded_model, gen_sentence)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    path = random.choice(model_paths)\n",
    "    loaded_model.load_weights(path)\n",
    "    print(\"\\n Loaded model from disk: \", path)\n",
    "    \n",
    "    create_passage(loaded_model, gen_sentence)\n",
    "    print(\"\\n ---------------------------------------------------------------------\")\n",
    "\n",
    "# compile loaded model\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in some text:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = input(\"Type in some text:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_int_conversion():\n",
    "    #basic characters in all books\n",
    "    unique_chars = [' ', '!', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    #turn characters into integers and integers into characters - chars should be sorted to keep consistency\n",
    "    char_to_int = {}\n",
    "    int_to_char = {}\n",
    "    for i, char in enumerate(sorted(set(unique_chars))):\n",
    "        char_to_int[char] = i\n",
    "        int_to_char[i] = char\n",
    "        \n",
    "    return char_to_int, int_to_char\n",
    "#     print('number of unique characters: ', len(char_to_int)) #should be 48 every time\n",
    "#     print('unique characters: ', list(char_to_int.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a list of all the path weights and the architecture\n",
    "def get_weights_and_arch():\n",
    "    round_path = \"models/\"\n",
    "    model_paths = []\n",
    "    for root, dirs, files in os.walk(round_path):\n",
    "        #file names in files path\n",
    "        for file in files:\n",
    "            if file.endswith('hdf5'):\n",
    "                model_paths.append(root+\"/\"+file)\n",
    "            elif file.endswith('model_8_architecture.json'):\n",
    "                architecture_path = root+\"/\"+file\n",
    "    #sort paths\n",
    "    model_paths.sort()\n",
    "#     print(architecture_path)\n",
    "    \n",
    "#     print(archi_paths[-1])\n",
    "    # load json architecture\n",
    "    json_file = open(architecture_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    #return model paths\n",
    "    return model_paths, loaded_model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sentence(sub_books_combined, sentence_length=50):\n",
    "#     gen_sentence = ''\n",
    "#     #create sentence by pulling a random piece of text from the corpus\n",
    "#     start_ind = random.randint(0, len(sub_books_combined) - sentence_length - 1)\n",
    "#     sentence = sub_books_combined[start_ind: start_ind+sentence_length]\n",
    "#     gen_sentence += sentence\n",
    "# #     print('original sentence: ', sentence)\n",
    "# #     print('\\n')\n",
    "#     return gen_sentence\n",
    "\n",
    "#creates new sentences\n",
    "def create_passage(model, sentence):\n",
    "#     sentence_length=50\n",
    "#     #full passage string\n",
    "#     sentence = create_sentence(sub_books_combined, sentence_length=sentence_length)\n",
    "\n",
    "    print('original sentence: ', sentence.split(\"  \")[-1])\n",
    "    print('\\n')\n",
    "    #predict the next 500 characters \n",
    "    gen_sentence = sentence\n",
    "    print(gen_sentence.split(\"  \")[-1], end=\"\", flush=True)\n",
    "    for i in range(300):\n",
    "#     period_cnt = 0\n",
    "#     while period_cnt != 2:\n",
    "        #turn single sentence into model format\n",
    "        x_pred = np.zeros((1, sentence_length, len(char_to_int)))\n",
    "        #fill tensor with correspoinding values\n",
    "        for k, c in enumerate(sentence):\n",
    "            x_ind = char_to_int[c]\n",
    "            x_pred[0, k, x_ind] = 1\n",
    "\n",
    "        #predict next character - returns predicted probabilities\n",
    "        prob_c = model.predict(x_pred, verbose=0)[0]\n",
    "        #turn to float64 - mulitnomial gives error otherwise\n",
    "        prob_c = np.asarray(prob_c).astype('float64')\n",
    "        #sample from the probability - try out difference softmax temperature values - 0.5 produced best results\n",
    "        log_prob = np.log(prob_c) / 0.5\n",
    "        exp_prob = np.exp(log_prob)\n",
    "        pred_prob = exp_prob/np.sum(exp_prob)\n",
    "        #sample from new probability distribution\n",
    "        p = np.random.multinomial(1, pred_prob, 1) \n",
    "        #get the probability position\n",
    "        prob_ind = np.argmax(p)\n",
    "\n",
    "        #turn prediction into a character\n",
    "        next_c = int_to_char[prob_ind]\n",
    "#         if next_c == '.':\n",
    "#             period_cnt += 1\n",
    "        #add character to generated sentence\n",
    "        gen_sentence += next_c\n",
    "        #get new sentence by sliding to index of sentence\n",
    "        sentence = sentence[1:]+next_c\n",
    "        print(next_c, end=\"\", flush=True)\n",
    "\n",
    "  \n",
    "    return gen_sentence.split(\"  \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sentence():\n",
    "    #take input from user\n",
    "    while True:\n",
    "        sentence = input(\"Type in some text: \")\n",
    "        sent_len = len(sentence)\n",
    "        #check if the user inputed anything\n",
    "        if sent_len > 0:\n",
    "            break\n",
    "        else:\n",
    "            print(\"You didn't enter anything in.\")\n",
    "            time.sleep(1.8)\n",
    "            clear_output()\n",
    "        \n",
    "#     print('old sentence length: ', sent_len)\n",
    "    \n",
    "    #check if the length is less than the length of the sentences the model was trained on\n",
    "    if sent_len < 50:\n",
    "        while sent_len < 50:\n",
    "            sentence = ' ' + sentence\n",
    "            sent_len = len(sentence)\n",
    "    #sentence has more characters than what was trained on\n",
    "    else:\n",
    "        #grab the last 50 characters\n",
    "        sentence = sentence[-50:]\n",
    "    \n",
    "    #lowercase everything\n",
    "    sentence = sentence.lower()\n",
    "        \n",
    "#     print('new_length: ', len(sentence))\n",
    "#     print(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the char to int conversion and vice versa\n",
    "char_to_int, int_to_char = get_char_int_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of all models and the architecture\n",
    "model_paths, loaded_model_json = get_weights_and_arch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #take input sentence from user\n",
    "    sentence = input_sentence()\n",
    "    clear_output()\n",
    "    \n",
    "    #load architecture\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    #pick random weights from list\n",
    "    path = random.choice(model_paths)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path)\n",
    "    print(\"\\n Loaded model from disk: \", path)\n",
    "    \n",
    "    create_passage(loaded_model, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in some text: my name is jeus\n",
      "\n",
      " Loaded model from disk:  models/round6/weights-improvement-29-1.4536-bigger.hdf5\n",
      "original sentence:   my name is jeus\n",
      "\n",
      "\n",
      " my name is jeust  the man. the piece of the tongue to be a counterit of brothers and a good hearts, and the full the word of that te thing shall need  in the world of the place  that i was to make the contrary of the company,  one the sense.                                                                          "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in some text: heloasdkfj asdjflk daskljf\n",
      "\n",
      " Loaded model from disk:  models/round3/weights-improvement-50-1.4546-bigger.hdf5\n",
      "original sentence:  heloasdkfj asdjflk daskljf\n",
      "\n",
      "\n",
      "heloasdkfj asdjflk daskljfically and had he had not united that her sire and were seen to deceive the      tears has been probably as the strange pleasant that she was considered the feeling of good work and the notions of encounter to hunger and who was a middle to the flower of the whales of the world which he was a shedde"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
