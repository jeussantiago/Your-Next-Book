{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all books combined:  74454677\n",
      "size of data:  5000000\n",
      "number of unique characters:  48\n",
      "sentence_length:  50\n",
      "num unique_chars:  48\n",
      "[\" knew that madame ratignolle's opinion in such a m\", \"new that madame ratignolle's opinion in such a mat\", \"w that madame ratignolle's opinion in such a matte\", \"that madame ratignolle's opinion in such a matter \", \"at madame ratignolle's opinion in such a matter wo\"]\n",
      "['a', 't', 'r', 'w', 'u']\n",
      "(2499975, 50, 48)\n",
      "(2499975, 48)\n"
     ]
    }
   ],
   "source": [
    "books_combined = open('books_combined.txt').read()\n",
    "print('length of all books combined: ', len(books_combined))\n",
    "\n",
    "#work with a subset of the books\n",
    "start_book_ind = 15000000\n",
    "end_book_ind = 20000000\n",
    "sub_books_combined = books_combined[start_book_ind: end_book_ind]\n",
    "print('size of data: ', len(sub_books_combined))\n",
    "\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "#turn characters into integers and integers into characters - chars should be sorted to keep consistency\n",
    "for i, char in enumerate(sorted(set(books_combined))):\n",
    "    char_to_int[char] = i\n",
    "    int_to_char[i] = char\n",
    "    \n",
    "print('number of unique characters: ', len(char_to_int)) #should be 48 every time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#returns a tensor for training\n",
    "def get_train(book, sentence_length=50):\n",
    "    sent = []\n",
    "    next_c = []\n",
    "    #get varying sentences of similar sizes - step for a size of 5 - 5 is an arbitraily chosen number\n",
    "    for i in range(0, len(book)-sentence_length, 2):\n",
    "        begin_char = i\n",
    "        end_char = i+sentence_length\n",
    "        #combine sentence to a sentence list\n",
    "        sent.append(book[begin_char: end_char])\n",
    "        #get the next character after the sentence\n",
    "        next_c.append(book[end_char])\n",
    "\n",
    "    print(sent[:5])\n",
    "    print(next_c[:5])\n",
    "\n",
    "    #turn into Tensors for training the model - using one hot encoding method\n",
    "    # 1 if char in sentence and 0 otherwise\n",
    "    unique_c_length = len(set(book)) # number of unique characters in text\n",
    "    num_sent = (len(sent)) #numer of sentences created\n",
    "    x = np.zeros((num_sent, sentence_length, unique_c_length), dtype=np.int8)\n",
    "    y = np.zeros((num_sent, unique_c_length), dtype=np.int8)\n",
    "\n",
    "    for i, sentence in enumerate(sent):\n",
    "        for k, c in enumerate(sentence):\n",
    "            c_ind = char_to_int[c]\n",
    "            x[i, k, c_ind] = 1\n",
    "\n",
    "        next_c_ind = char_to_int[next_c[i]]\n",
    "        y[i, next_c_ind] = 1\n",
    "\n",
    "\n",
    "    return x,y\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "sentence_length = 50\n",
    "num_unique_chars = len(set(books_combined))\n",
    "print(\"sentence_length: \", sentence_length)\n",
    "print(\"num unique_chars: \", num_unique_chars)\n",
    "\n",
    "#create tensors\n",
    "x, y = get_train(sub_books_combined, sentence_length=sentence_length)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "698752/999990 [===================>..........] - ETA: 6:32 - loss: 1.4459"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-01bb4ac3f237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#save models that perform best\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#create network\n",
    "model = Sequential()\n",
    "#128 nodes are used b/c the current network is small\n",
    "model.add(LSTM(128, input_shape=(sentence_length, num_unique_chars)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dropout(0.2))\n",
    "#add the output layer\n",
    "model.add(Dense(num_unique_chars, activation='softmax'))\n",
    "#load previous weights\n",
    "weights_filename = 'models/round4/model_4.h5'\n",
    "model.load_weights(weights_filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(x, y, epochs=50, batch_size=128, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates new sentence\n",
    "def create_passage(model):\n",
    "    #complete passage string\n",
    "    gen_sentence = ''\n",
    "\n",
    "    #create sentence\n",
    "    start_ind = random.randint(0, len(sub_books_combined) - sentence_length - 1)\n",
    "    sentence = sub_books_combined[start_ind: start_ind+sentence_length]\n",
    "    gen_sentence += sentence\n",
    "    print('original sentenc: ', sentence)\n",
    "\n",
    "    for i in range(500):\n",
    "    #turn sentence into model format\n",
    "        x_pred = np.zeros((1, sentence_length, len(char_to_int)))\n",
    "        for k, c in enumerate(sentence):\n",
    "            x_ind = char_to_int[c]\n",
    "            x_pred[0, k, x_ind] = 1\n",
    "\n",
    "        #predict next character - returns predicted probabilities\n",
    "        prob_c = model.predict(x_pred, verbose=0)[0]\n",
    "        #turn to float64 - mulitnomial gives error otherwise\n",
    "        prob_c = np.asarray(prob_c).astype('float64')\n",
    "        #     print(prob_c)\n",
    "        #sample from the probability \n",
    "        log_prob = np.log(prob_c) / 0.5\n",
    "        #     print(log_prob)\n",
    "        exp_prob = np.exp(log_prob)\n",
    "        #     print(exp_prob)\n",
    "        pred_prob = exp_prob/np.sum(exp_prob)\n",
    "        #     print(pred_prob)\n",
    "        p = np.random.multinomial(1, pred_prob, 1) \n",
    "        #     print(p)\n",
    "        prob_ind = np.argmax(p)\n",
    "        #     print(prob_ind)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #turn int to character\n",
    "        next_c = int_to_char[prob_ind]\n",
    "        #add character to generated sentence\n",
    "        gen_sentence += next_c\n",
    "        #     print(gen_sentence)\n",
    "        #get new sentence by sliding to index of sentence\n",
    "        sentence = sentence[1:]+next_c\n",
    "\n",
    "\n",
    "    return gen_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test out creating a passage using some of the passage within the books\n",
    "print(create_passage(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original sentenc:  sly          stirred us to glory and gave me these<br>\n",
    "sly          stirred us to glory and gave me these of the sense of the strong and being in a state and the street the soul for the spoken to scarne the fire destroyed and with the subjects best notice and absolute stream by the death of a contrary of the concerning the supportions is been ever known to the interest of the carriage in the man project gutenberg-tm electronic works in a most common-wealth and one of one final and the more not one of the wants of the consequence where the present stood the other were the small and project gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_4_architecture.json\", \"w+\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_4.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(38), history_dict['loss'])\n",
    "plt.title('Training Data Loss Function')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model architecture\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data/ predict\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
